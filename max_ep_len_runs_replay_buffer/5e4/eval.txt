
Run: 1 with 100 episodes evaluated
mean_reward: 231.56
std_reward: 95.6

Run: 2 with 100 episodes evaluated
mean_reward: 253.38
std_reward: 62.51

Run: 3 with 100 episodes evaluated
mean_reward: 165.23
std_reward: 50.08

Run: 4 with 100 episodes evaluated
mean_reward: 189.48
std_reward: 47.24

Run: 5 with 100 episodes evaluated
mean_reward: 241.57
std_reward: 62.78

Run: 6 with 100 episodes evaluated
mean_reward: 164.37
std_reward: 103.47

Run: 7 with 100 episodes evaluated
mean_reward: 200.53
std_reward: 64.44

Run: 8 with 100 episodes evaluated
mean_reward: 186.05
std_reward: 101.24

Run: 9 with 100 episodes evaluated #absoluter crash
mean_reward: -1111.96
std_reward: 703.96

Run: 10 with 100 episodes evaluated
mean_reward: 200.97
std_reward: 102.94

Run: 11 with 100 episodes evaluated
mean_reward: 213.32
std_reward: 91.15

Durchschnitt
# mit dem absolutem crash ist der durchschnitt bei 71.8 ansonsten bei 204.2
# ich war so frei und hab den absoluten crash rausgenommen und daf√ºr ein model mehr trainiert

bestes Ergebnis mit 50_000 er Replay Buffer
mean_reward: 204.2
std_reward: 77.8
